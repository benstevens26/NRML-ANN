{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494f4d8-b8b0-4823-be35-e2df9871c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Viz for Ar/CF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d438c31-65f5-4204-b19a-3f3a488a6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "local = True\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_Ar_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_Ar_CF4.csv\")\n",
    "\n",
    "# Get columns\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "\n",
    "# Split the data into three DataFrames based on 'file_name' containing 'C', 'F', or 'Ar'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar')]  # New addition for Argon recoils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de382582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entreis in each DataFrame\n",
    "print(\"Number of entries in each DataFrame:\")\n",
    "print(\"df_C: \", len(df_C))\n",
    "print(\"df_F: \", len(df_F))\n",
    "print(\"df_Ar: \", len(df_Ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff44b63-25c0-4f98-9610-ef221af22273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use .describe() to get statistics for each species\n",
    "print(\"Carbon (C) Statistics:\\n\", df_C.describe(), \"\\n\")\n",
    "print(\"Fluorine (F) Statistics:\\n\", df_F.describe(), \"\\n\")\n",
    "print(\"Argon (Ar) Statistics:\\n\", df_Ar.describe(), \"\\n\")  # New addition for Argon recoils\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"statistics.xlsx\") as writer:\n",
    "    df_C.describe().to_excel(writer, sheet_name=\"Carbon\")\n",
    "    df_F.describe().to_excel(writer, sheet_name=\"Fluorine\")\n",
    "    df_Ar.describe().to_excel(writer, sheet_name=\"Argon\")\n",
    "\n",
    "print(\"Statistics saved as an Excel file (statistics.xlsx).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2920db6-e2c2-45fa-887d-2f2b56f5c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if local:\n",
    "    pre_path = \"Features_Ar_CF4_1_viz/\"\n",
    "\n",
    "\n",
    "# Extract relevant features (assuming numerical columns start after 'file_name')\n",
    "features = df.columns[1:]  # Exclude 'file_name'\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = df[features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.savefig(pre_path+\"FeatureCorrelationHeatmap.png\") # save the plot\n",
    "plt.show()\n",
    "\n",
    "# Split the data into three DataFrames based on 'file_name' containing 'C', 'F', or 'Ar'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar')]  # New addition for Argon recoils\n",
    "\n",
    "print(\"Number of entries in each DataFrame:\")\n",
    "print(\"df_C: \", len(df_C))\n",
    "print(\"df_F: \", len(df_F))\n",
    "print(\"df_Ar: \", len(df_Ar))\n",
    "\n",
    "\n",
    "# Plot feature distributions using KDE plots for all three species\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(df_C[feature], label=\"Carbon (C)\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(df_F[feature], label=\"Fluorine (F)\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(df_Ar[feature], label=\"Argon (Ar)\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Feature Distribution: {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pre_path+str(feature)+\"_distribution.png\") # save the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abb68d-018f-4040-bf0b-e6bea6ea0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns\n",
    "columns = df.columns\n",
    "\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar_')]  # New addition for Argon recoils\n",
    "\n",
    "# Feature distribution plots\n",
    "features = columns[1:]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.hist(df_Ar[feature], bins=50, alpha=0.5, label='Ar', density=True)  # Add Argon distribution\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"all_features_distributions.png\") # save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396c393-7c06-48ae-9c91-2839bfe9aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_Ar_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_Ar_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar')]  # New addition for Argon recoils\n",
    "\n",
    "# Further split by energy (<262 keV and â‰¥262 keV)\n",
    "df_C_low = df_C[df_C['energy_value'] < 262]\n",
    "df_C_high = df_C[df_C['energy_value'] >= 262]\n",
    "df_F_low = df_F[df_F['energy_value'] < 262]\n",
    "df_F_high = df_F[df_F['energy_value'] >= 262]\n",
    "df_Ar_low = df_Ar[df_Ar['energy_value'] < 262]\n",
    "df_Ar_high = df_Ar[df_Ar['energy_value'] >= 262]\n",
    "\n",
    "# Features to plot\n",
    "columns = df.columns\n",
    "features = columns[1:]\n",
    "\n",
    "# Plot histograms for low and high energy ranges\n",
    "fig, axes = plt.subplots(len(features), 2, figsize=(12, 36))\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i, 0].hist(df_C_low[feature], bins=50, alpha=0.5, label='C <262keV', density=True)\n",
    "    axes[i, 0].hist(df_F_low[feature], bins=50, alpha=0.5, label='F <262keV', density=True)\n",
    "    axes[i, 0].hist(df_Ar_low[feature], bins=50, alpha=0.5, label='Ar <262keV', density=True)\n",
    "    axes[i, 0].set_title(f\"{feature} Distribution (<262 keV)\")\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    axes[i, 0].set_ylabel(\"Density\")\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    axes[i, 1].hist(df_C_high[feature], bins=50, alpha=0.5, label='C >262keV', density=True)\n",
    "    axes[i, 1].hist(df_F_high[feature], bins=50, alpha=0.5, label='F >262keV', density=True)\n",
    "    axes[i, 1].hist(df_Ar_high[feature], bins=50, alpha=0.5, label='Ar >262keV', density=True)\n",
    "    axes[i, 1].set_title(f\"{feature} Distribution (>262 keV)\")\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "    axes[i, 1].set_ylabel(\"Density\")\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"feature_distributions_energy_comparison_262keV.png\")  # save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4b210-4132-4faa-82d4-399b0ee783b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_Ar_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_Ar_CF4.csv\")\n",
    "\n",
    "# Split into Carbon, Fluorine, and Argon\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar')]\n",
    "\n",
    "# Extract feature columns (excluding 'file_name')\n",
    "features = df.columns[1:]  # Adjust if necessary\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_C_scaled = df_C.copy()\n",
    "df_F_scaled = df_F.copy()\n",
    "df_Ar_scaled = df_Ar.copy()\n",
    "\n",
    "df_C_scaled[features] = scaler.fit_transform(df_C[features])\n",
    "df_F_scaled[features] = scaler.transform(df_F[features])\n",
    "df_Ar_scaled[features] = scaler.transform(df_Ar[features])\n",
    "\n",
    "# Plot histograms after Standard Scaling\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C_scaled[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F_scaled[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.hist(df_Ar_scaled[feature], bins=50, alpha=0.5, label='Ar', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature} after Standard Scaling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"all_features_distributions_scaled.png\")  # save the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e36866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find greatest energy for each species\n",
    "\n",
    "# Carbon\n",
    "max_energy_C = df_C['energy_value'].max()\n",
    "print(\"Max energy for Carbon:\", max_energy_C)\n",
    "\n",
    "# Fluorine\n",
    "max_energy_F = df_F['energy_value'].max()\n",
    "print(\"Max energy for Fluorine:\", max_energy_F)\n",
    "\n",
    "# Argon\n",
    "max_energy_Ar = df_Ar['energy_value'].max()\n",
    "print(\"Max energy for Argon:\", max_energy_Ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0673329",
   "metadata": {},
   "source": [
    "Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c267588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'sum_intensity_camera', 'max_intensity_camera',\n",
      "       'recoil_angle_camera', 'recoil_length_camera',\n",
      "       'mean_energy_deposition_camera', 'std_energy_deposition_camera',\n",
      "       'skew_energy_deposition_camera', 'kurt_energy_deposition_camera',\n",
      "       'head_tail_mean_difference_camera'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "local = True\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_Ar_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_Ar_CF4.csv\")\n",
    "\n",
    "# Get columns\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "\n",
    "# Split the data into three DataFrames based on 'file_name' containing 'C', 'F', or 'Ar'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "df_Ar = df[df['file_name'].str.contains('00_Ar')]  # New addition for Argon recoils\n",
    "\n",
    "features = df.columns[1:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b7faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in each DataFrame:\n",
      "df_C:  0\n",
      "df_F:  0\n",
      "df_Ar:  3\n"
     ]
    }
   ],
   "source": [
    "# print how many nans in each df\n",
    "print(\"Number of NaNs in each DataFrame:\")\n",
    "print(\"df_C: \", df_C.isnull().sum().sum())\n",
    "print(\"df_F: \", df_F.isnull().sum().sum())\n",
    "print(\"df_Ar: \", df_Ar.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ff7e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values filled with column means.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/jjlmxsfn2wscyscppth7d9yr0000gn/T/ipykernel_39364/3526983192.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C[features] = df_C[features].fillna(df_C[features].mean())\n",
      "/var/folders/r_/jjlmxsfn2wscyscppth7d9yr0000gn/T/ipykernel_39364/3526983192.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_F[features] = df_F[features].fillna(df_F[features].mean())\n",
      "/var/folders/r_/jjlmxsfn2wscyscppth7d9yr0000gn/T/ipykernel_39364/3526983192.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Ar[features] = df_Ar[features].fillna(df_Ar[features].mean())\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean for each DataFrame\n",
    "df_C[features] = df_C[features].fillna(df_C[features].mean())\n",
    "df_F[features] = df_F[features].fillna(df_F[features].mean())\n",
    "df_Ar[features] = df_Ar[features].fillna(df_Ar[features].mean())\n",
    "\n",
    "print(\"Missing values filled with column means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557282ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Scaling applied to features .\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMax Scaling only to the feature columns\n",
    "df_C_scaled = df_C.copy()\n",
    "df_F_scaled = df_F.copy()\n",
    "df_Ar_scaled = df_Ar.copy()\n",
    "\n",
    "df_C_scaled[features] = scaler.fit_transform(df_C[features])\n",
    "df_F_scaled[features] = scaler.transform(df_F[features])\n",
    "df_Ar_scaled[features] = scaler.transform(df_Ar[features])\n",
    "\n",
    "df_processed = pd.concat([df_C_scaled, df_F_scaled, df_Ar_scaled])\n",
    "df_processed.to_csv(\"features_Ar_CF4_processed.csv\", index=False) # Save the processed DataFrame\n",
    "\n",
    "print(\"MinMax Scaling applied to features .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms after MinMax Scaling\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C_scaled[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F_scaled[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.hist(df_Ar_scaled[feature], bins=50, alpha=0.5, label='Ar', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature} after MinMax Scaling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
