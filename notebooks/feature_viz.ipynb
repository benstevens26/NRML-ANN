{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for exploratory data analysis of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Import Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_name', 'sum_intensity_camera', 'max_intensity_camera',\n",
      "       'recoil_angle_camera', 'recoil_length_camera',\n",
      "       'mean_energy_deposition_camera', 'std_energy_deposition_camera',\n",
      "       'skew_energy_deposition_camera', 'kurt_energy_deposition_camera',\n",
      "       'head_tail_mean_difference_camera'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "local = True\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Get columns\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "\n",
    "# Split the data into two DataFrames based on 'file_name' containing 'C' or 'F'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basic Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entreis in each DataFrame\n",
    "print(\"Number of entries in each DataFrame:\")\n",
    "print(\"df_C: \", len(df_C))\n",
    "print(\"df_F: \", len(df_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe() to get statistics for each species\n",
    "print(\"Carbon (C) Statistics:\\n\", df_C.describe(), \"\\n\")\n",
    "print(\"Fluorine (F) Statistics:\\n\", df_F.describe(), \"\\n\")\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"statistics.xlsx\") as writer:\n",
    "    df_C.describe().to_excel(writer, sheet_name=\"Carbon\")\n",
    "    df_F.describe().to_excel(writer, sheet_name=\"Fluorine\")\n",
    "\n",
    "print(\"Statistics saved as an Excel file (statistics.xlsx).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if local:\n",
    "    pre_path = \"Features_CF4_1_viz/\"  # Update path for CF4-only dataset\n",
    "\n",
    "# Extract relevant features (assuming numerical columns start after 'file_name')\n",
    "features = df.columns[1:]  # Exclude 'file_name'\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = df[features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.savefig(pre_path+\"FeatureCorrelationHeatmap.png\")  # Save the plot\n",
    "plt.show()\n",
    "\n",
    "# Split the data into two DataFrames based on 'file_name' containing 'C' or 'F'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "print(\"Number of entries in each DataFrame:\")\n",
    "print(\"df_C: \", len(df_C))\n",
    "print(\"df_F: \", len(df_F))\n",
    "\n",
    "# Plot feature distributions using KDE plots for Carbon and Fluorine only\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(df_C[feature], label=\"Carbon (C)\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(df_F[feature], label=\"Fluorine (F)\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Feature Distribution: {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.savefig(pre_path+str(feature)+\"_distribution.png\")  # Save the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns\n",
    "columns = df.columns\n",
    "\n",
    "# Split the data into two DataFrames based on 'file_name' containing 'C' or 'F'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "# Feature distribution plots\n",
    "features = columns[1:]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"all_features_distributions.png\")  # Save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "# Further split by energy (<30 keV and â‰¥30 keV)\n",
    "df_C_low = df_C[df_C['energy_value'] < 30]\n",
    "df_C_high = df_C[df_C['energy_value'] >= 30]\n",
    "df_F_low = df_F[df_F['energy_value'] < 30]\n",
    "df_F_high = df_F[df_F['energy_value'] >= 30]\n",
    "\n",
    "# Features to plot\n",
    "columns = df.columns\n",
    "features = columns[1:]\n",
    "\n",
    "# Plot histograms for low and high energy ranges\n",
    "fig, axes = plt.subplots(len(features), 2, figsize=(12, 36))\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i, 0].hist(df_C_low[feature], bins=50, alpha=0.5, label='C <30keV', density=True)\n",
    "    axes[i, 0].hist(df_F_low[feature], bins=50, alpha=0.5, label='F <30keV', density=True)\n",
    "    axes[i, 0].set_title(f\"{feature} Distribution (<30 keV)\")\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    axes[i, 0].set_ylabel(\"Density\")\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    axes[i, 1].hist(df_C_high[feature], bins=50, alpha=0.5, label='C >30keV', density=True)\n",
    "    axes[i, 1].hist(df_F_high[feature], bins=50, alpha=0.5, label='F >30keV', density=True)\n",
    "    axes[i, 1].set_title(f\"{feature} Distribution (>30 keV)\")\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "    axes[i, 1].set_ylabel(\"Density\")\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"feature_distributions_energy_comparison_30keV.png\")  # save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "# Extract feature columns (excluding 'file_name')\n",
    "features = df.columns[1:]  # Adjust if necessary\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_C_scaled = df_C.copy()\n",
    "df_F_scaled = df_F.copy()\n",
    "\n",
    "df_C_scaled[features] = scaler.fit_transform(df_C[features])\n",
    "df_F_scaled[features] = scaler.transform(df_F[features])\n",
    "\n",
    "# Plot histograms after Standard Scaling\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C_scaled[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F_scaled[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature} after Standard Scaling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"all_features_distributions_standardscaled.png\")  # Save the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find greatest energy for each species\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "# Carbon\n",
    "max_energy_C = df_C['energy_value'].max()\n",
    "print(\"Max energy for Carbon:\", max_energy_C)\n",
    "\n",
    "# Fluorine\n",
    "max_energy_F = df_F['energy_value'].max()\n",
    "print(\"Max energy for Fluorine:\", max_energy_F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Get columns\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "\n",
    "# Split the data into two DataFrames based on 'file_name' containing 'C' or 'F'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# drop nans\n",
    "df_C = df_C.dropna()\n",
    "df_F = df_F.dropna()\n",
    "\n",
    "pca = PCA()\n",
    "df_C_pca = pca.fit_transform(df_C[features])\n",
    "df_F_pca = pca.transform(df_F[features])\n",
    "\n",
    "# Explained variance plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid()\n",
    "# plt.savefig(\"PCA.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "local = False\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('_C_')]\n",
    "df_F = df[df['file_name'].str.contains('_F_')]\n",
    "\n",
    "# Further split by energy\n",
    "df_C_low = df_C[df_C['energy_value'] < 30]\n",
    "df_C_high = df_C[df_C['energy_value'] >= 30]\n",
    "df_F_low = df_F[df_F['energy_value'] < 30]\n",
    "df_F_high = df_F[df_F['energy_value'] >= 30]\n",
    "\n",
    "# Features to plot\n",
    "columns = df.columns\n",
    "features = columns[1:]\n",
    "\n",
    "# Plot histograms for low and high energy ranges\n",
    "fig, axes = plt.subplots(len(features), 2, figsize=(12, 15))\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i, 0].hist(df_C_low[feature], bins=50, alpha=0.5, label='C <30keV', density=True)\n",
    "    axes[i, 0].hist(df_F_low[feature], bins=50, alpha=0.5, label='F <30keV', density=True)\n",
    "    axes[i, 0].set_title(f\"{feature} Distribution (<30 keV)\")\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    axes[i, 0].set_ylabel(\"Density\")\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    axes[i, 1].hist(df_C_high[feature], bins=50, alpha=0.5, label='C >30keV', density=True)\n",
    "    axes[i, 1].hist(df_F_high[feature], bins=50, alpha=0.5, label='F >30keV', density=True)\n",
    "    axes[i, 1].set_title(f\"{feature} Distribution (>30 keV)\")\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "    axes[i, 1].set_ylabel(\"Density\")\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "local = False\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('_C_')]\n",
    "df_F = df[df['file_name'].str.contains('_F_')]\n",
    "\n",
    "# Features to plot (excluding 'file_name', 'sum_intensity_camera', 'energy_value')\n",
    "features = ['max_intensity_camera', 'recoil_angle_camera', 'recoil_length_camera',\n",
    "            'mean_energy_deposition_camera', 'std_energy_deposition_camera',\n",
    "            'skew_energy_deposition_camera', 'kurt_energy_deposition_camera',\n",
    "            'head_tail_mean_difference_camera']\n",
    "\n",
    "def plot_histograms(energy_threshold):\n",
    "    df_C_low = df_C[df_C['energy_value'] < energy_threshold]\n",
    "    df_C_high = df_C[df_C['energy_value'] >= energy_threshold]\n",
    "    df_F_low = df_F[df_F['energy_value'] < energy_threshold]\n",
    "    df_F_high = df_F[df_F['energy_value'] >= energy_threshold]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(features), 2, figsize=(12, 15))\n",
    "    for i, feature in enumerate(features):\n",
    "        axes[i, 0].hist(df_C_low[feature], bins=50, alpha=0.5, label='C <{:.1f}keV'.format(energy_threshold), density=True)\n",
    "        axes[i, 0].hist(df_F_low[feature], bins=50, alpha=0.5, label='F <{:.1f}keV'.format(energy_threshold), density=True)\n",
    "        axes[i, 0].set_title(f\"{feature} Distribution (<{np.round(energy_threshold,3)} keV)\")\n",
    "        axes[i, 0].set_xlabel(feature)\n",
    "        axes[i, 0].set_ylabel(\"Density\")\n",
    "        axes[i, 0].legend()\n",
    "        \n",
    "        axes[i, 1].hist(df_C_high[feature], bins=50, alpha=0.5, label='C >{:.1f}keV'.format(energy_threshold), density=True)\n",
    "        axes[i, 1].hist(df_F_high[feature], bins=50, alpha=0.5, label='F >{:.1f}keV'.format(energy_threshold), density=True)\n",
    "        axes[i, 1].set_title(f\"{feature} Distribution (>{np.round(energy_threshold,3)} keV)\")\n",
    "        axes[i, 1].set_xlabel(feature)\n",
    "        axes[i, 1].set_ylabel(\"Density\")\n",
    "        axes[i, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "interact(plot_histograms, energy_threshold=FloatSlider(min=5, max=500, step=5, value=30));\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"energy_feature_distribution_comparison_100keV.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS tests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "local = False\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('_C_')]\n",
    "df_F = df[df['file_name'].str.contains('_F_')]\n",
    "\n",
    "# Features to compare (excluding 'file_name', 'sum_intensity_camera', 'energy_value')\n",
    "features = ['max_intensity_camera', 'recoil_angle_camera', 'recoil_length_camera',\n",
    "            'mean_energy_deposition_camera', 'std_energy_deposition_camera',\n",
    "            'skew_energy_deposition_camera', 'kurt_energy_deposition_camera',\n",
    "            'head_tail_mean_difference_camera']\n",
    "\n",
    "# Perform KS test for each feature\n",
    "ks_results = {}\n",
    "for feature in features:\n",
    "    ks_stat, p_value = ks_2samp(df_C[feature].dropna(), df_F[feature].dropna())\n",
    "    ks_results[feature] = {'KS Statistic': ks_stat, 'P-Value': p_value}\n",
    "\n",
    "# Convert to DataFrame and display results\n",
    "ks_df = pd.DataFrame.from_dict(ks_results, orient='index')\n",
    "print(ks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS tests at low energies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import ks_2samp\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "local = False\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Extract energy from file_name using regex\n",
    "def extract_energy(file_name):\n",
    "    match = re.search(r\"(\\d+\\.\\d+)keV\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df['energy_value'] = df['file_name'].apply(extract_energy)\n",
    "\n",
    "# Remove rows with NaN energy\n",
    "df = df.dropna(subset=['energy_value'])\n",
    "\n",
    "# Split into Carbon and Fluorine\n",
    "df_C = df[df['file_name'].str.contains('_C_')]\n",
    "df_F = df[df['file_name'].str.contains('_F_')]\n",
    "\n",
    "# Features to compare (excluding 'file_name', 'sum_intensity_camera', 'energy_value')\n",
    "features = ['max_intensity_camera', 'recoil_angle_camera', 'recoil_length_camera',\n",
    "            'mean_energy_deposition_camera', 'std_energy_deposition_camera',\n",
    "            'skew_energy_deposition_camera', 'kurt_energy_deposition_camera',\n",
    "            'head_tail_mean_difference_camera']\n",
    "\n",
    "def ks_test_by_energy(energy_threshold):\n",
    "    df_C_low = df_C[df_C['energy_value'] < energy_threshold]\n",
    "    df_C_high = df_C[df_C['energy_value'] >= energy_threshold]\n",
    "    df_F_low = df_F[df_F['energy_value'] < energy_threshold]\n",
    "    df_F_high = df_F[df_F['energy_value'] >= energy_threshold]\n",
    "    \n",
    "    ks_results_low = {}\n",
    "    ks_results_high = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        ks_stat_low, p_value_low = ks_2samp(df_C_low[feature].dropna(), df_F_low[feature].dropna())\n",
    "        ks_results_low[feature] = {'KS Statistic': ks_stat_low, 'P-Value': p_value_low}\n",
    "        \n",
    "        ks_stat_high, p_value_high = ks_2samp(df_C_high[feature].dropna(), df_F_high[feature].dropna())\n",
    "        ks_results_high[feature] = {'KS Statistic': ks_stat_high, 'P-Value': p_value_high}\n",
    "    \n",
    "    ks_df_low = pd.DataFrame.from_dict(ks_results_low, orient='index')\n",
    "    ks_df_high = pd.DataFrame.from_dict(ks_results_high, orient='index')\n",
    "    \n",
    "    print(f\"KS Test Results for < {energy_threshold} keV\")\n",
    "    print(ks_df_low)\n",
    "    print(\"\\n\")\n",
    "    print(f\"KS Test Results for > {energy_threshold} keV\")\n",
    "    print(ks_df_high)\n",
    "\n",
    "# Interactive widget\n",
    "interact(ks_test_by_energy, energy_threshold=FloatSlider(min=5, max=600, step=5, value=30));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "local = True\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "if local:\n",
    "    df = pd.read_csv(\"../ANN-code/Data/features_CF4.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"../ANN-code/features_CF4.csv\")\n",
    "\n",
    "# Get columns\n",
    "columns = df.columns\n",
    "print(columns)\n",
    "\n",
    "# Split the data into two DataFrames based on 'file_name' containing 'C' or 'F'\n",
    "df_C = df[df['file_name'].str.contains('00_C_')]\n",
    "df_F = df[df['file_name'].str.contains('00_F_')]\n",
    "\n",
    "# Define feature columns (excluding 'file_name')\n",
    "features = df.columns[1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many nans in each df\n",
    "print(\"Number of NaNs in each DataFrame:\")\n",
    "print(\"df_C: \", df_C.isnull().sum().sum())\n",
    "print(\"df_F: \", df_F.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean for each DataFrame\n",
    "df_C[features] = df_C[features].fillna(df_C[features].mean())\n",
    "df_F[features] = df_F[features].fillna(df_F[features].mean())\n",
    "\n",
    "\n",
    "print(\"Missing values filled with column means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMax Scaling only to the feature columns\n",
    "df_C_scaled = df_C.copy()\n",
    "df_F_scaled = df_F.copy()\n",
    "\n",
    "df_C_scaled[features] = scaler.fit_transform(df_C[features])\n",
    "df_F_scaled[features] = scaler.transform(df_F[features])\n",
    "\n",
    "\n",
    "df_processed = pd.concat([df_C_scaled, df_F_scaled])\n",
    "df_processed.to_csv(\"features_CF4_processed.csv\", index=False) # Save the processed DataFrame\n",
    "\n",
    "print(\"MinMax Scaling applied to features .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pre_path = \"Features_CF4_1_viz/\"\n",
    "\n",
    "# Plot histograms after MinMax Scaling\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.hist(df_C_scaled[feature], bins=50, alpha=0.5, label='C', density=True)\n",
    "    plt.hist(df_F_scaled[feature], bins=50, alpha=0.5, label='F', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {feature} after MinMax Scaling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(pre_path+\"all_features_distributions_minmaxscaled.png\")  # Save the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
